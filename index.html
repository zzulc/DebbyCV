<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Juncheng Li, Li Juncheng, Juncheng, East China Normal University, The Chinese University of Hong Kong, Shanghai University, 李俊诚, 俊诚, 华东师范大学, 香港中文大学，上海大学"> 
<meta name="description" content="Juncheng Li's home page">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Juncheng Li</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
</head>

<style>
	.scroll-container {
	  width: 940px; /* 容器宽度 */
	  height: 170px; /* 容器高度 */
	  overflow: auto; /* 当内容超出容器时显示滚动条 */
	  border: 1px solid #ccc; /* 容器边框 */
	  padding: 10px; /* 内边距 */
	}
</style>


<body>

 <!-- <div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/CV-JunchengLi" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style> -->

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Juncheng Li (李俊诚)</h1> 
				</div>

				<p>
					Assistant Professor<br>
					School of Communication & Information Engineering,<br>
					Shanghai University,<br>
					T807, Xiangying Building, Baoshan, Shanghai.<br>
					<br>
					Email: cvjunchengli[at]gmail.com  & junchengli[at]shu.edu.cn<br>
					<br>
					<font color="red">I'm always looking for self-motivated students working with me on computer vision, image processing, and medical image analysis. For prospective students, please send me an email with your CV and transcript.</font> 	       
				</p>

				<br>
				<!-- <p>
					<em>Success is not final, failure is not fatal, it is the courage to continue that counts.--Churchill</em>
				</p> -->

				<p> 
					<!-- <a href="https://github.com/CV-JunchengLi", target="_blank"><img src="./pic/cv_s.png" height="30px" style="margin-bottom:-3px"></a> -->
					<!-- <a href="JunchengLi-CV.pdf", target="_blank"><img src="./pic/cv_s.png" height="30px" style="margin-bottom:-3px"></a> -->
					<a href="https://scholar.google.com.hk/citations?user=a5jkbmkAAAAJ&hl=zh-CN", target="_blank"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/CV-JunchengLi", target="_blank"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
					<a href="index_zw.html", target="_blank"><img src="./pic/zw.png" height="30px" style="margin-bottom:-3px"></a>
				</p><br>
			</td>
			<td>
				<img src="./pic/JunchengLi.jpeg" border="0" width="200"><br>
			</td>
		</tr>
		<tr>
		</tr>
	</tbody>
</table>

<h2>Biography</h2>
<p style="text-align:justify; text-justify:inter-ideograph;">
	I received the Ph.D. degree from the School of Computer Science and Technology, East China Normal University (ECNU), China, in 2021, advised by <b>Prof. <a href="https://faculty.ecnu.edu.cn/_s16/zgx2/main.psp", target="_blank">Guixu Zhang</a></b>. I also served as a Postdoctoral Fellow at the Center for Mathematical Artificial Intelligence, The Chinese University of Hong Kong, advised by <b> Prof. <a href="https://scholar.google.com.hk/citations?user=2yyTgRwAAAAJ&hl=zh-CN", target="_blank">Tieyong Zeng</a></b>, in 2021-2022. My research interests include artificial intelligence and its applications to computer vision (e.g., image segmentation, object detection) and image processing (e.g., image super-resolution, image restoration under adverse weather, medical image processing). I have published more than 50 papers in top journals and conferences, including ACM Computing Survey, IEEE TIP\TNNLS\TMM\TCSVT\TMI, CVPR, ECCV, ICCV, AAAI, IJCAI, and MICCAI. Meanwhile, I received several premium awards, including the first prize for Innovation Achievements in Industry-Academia-Research Cooperation in China 2023, the Outstanding Ph.D. Graduates in Shanghai 2021, the CUHK Research Fellowship Scheme 2021, the winner of 2019 ICCV-AIM (Example-based RAW to RGB Mapping Challenge), etc. I also served as a reviewer for more than 30 international conferences/journals, including TPAMI, TIP,TNNLS, TMM, TCSVT, CVPR, ICCV, ECCV, and MICCAI.
</p>

<table id="tbPublications" width="100%">
	<tbody> 
		<tr>	
			<td width="206">
			<img src="./pic/Wechat.jpg" width="200" height = "200" style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td>Intelligent Imaging Computing Lab (IIC Lab)</td><br>
			<td>Welcome to follow!</td><br>
			</td>
		</tr>
	</tbody>
</table>


<h2>News</h2>
<table style="border-spacing:2px">
	<tbody>
		<tr><td>I will serve as a SPC for ECAI-25.</td></tr>
		<tr><td>One paper (IEEE TMM) is selected as Highly Cited Papers in the latest issue of ESI Index, 2025.</td></tr>
		<tr><td>I will serve as a PC Member for IJCAI-25.</td></tr>
		<tr><td>One paper (IEEE TIP) is selected as Highly Cited Papers in the latest issue of ESI Index, 2024.</td></tr>
		<tr><td>Selected into the World's Top 2% Scientists list, 2023.</td></tr>
		<tr><td>One paper (IEEE TMM) is selected as Highly Cited Papers in the latest issue of ESI Index, 2023.</td></tr>
		<tr><td>Selected into “Yang Fan Plan” of Shanghai, 2023.</td></tr>
	</tbody>
</table>


<h2>Papers News</h2>
<div class="scroll-container">
<table style="border-spacing:2px">
	<tbody>
		<tr><td>Congratulations! MSRN has reached 1,000 citations!</td></tr>
		<tr><td>One paper is accepted by ESWA, 2025.</td></tr>
		<tr><td>One paper is accepted by IEEE JBHI, 2025.</td></tr>
		<tr><td>One paper is accepted by IEEE TMI, 2025.</td></tr>
		<tr><td>One paper is accepted by ESWA, 2025.</td></tr>
		<tr><td>One paper is accepted by IEEE JBHI, 2024.</td></tr>
		<tr><td>One paper is accepted by CIBM, 2024.</td></tr>
		<tr><td>One paper is accepted by IEEE TCSVT, 2024.</td></tr>
		<tr><td>One paper is accepted by IEEE TMM, 2024.</td></tr>
		<tr><td>One paper is accepted by CIBM, 2024.</td></tr>
		<tr><td>One paper is accepted by IEEE TIM, 2024.</td></tr>
		<tr><td>One paper is accepted by Information Processing and Management, 2024.</td></tr>
		<tr><td>One paper is accepted by IEEE TMI, 2024.</td></tr>
		<tr><td>One paper is accepted by ESWA, 2024.</td></tr>
		<tr><td>One paper is accepted by MICCAI, 2024. (Oral)</td></tr>
		<tr><td>One paper is accepted by Neural Networks, 2024.</td></tr>
		<tr><td>One paper is accepted by IEEE JBHI, 2024.</td></tr>
		<tr><td>One paper is accepted by ACM Computing Surveys, 2024.</td></tr>
		<tr><td>One paper is accepted by IEEE TMI, 2024.</td></tr>
		<tr><td>One paper is accepted by CVPR, 2024.</td></tr>
		<tr><td>One paper is accepted by IEEE TMI, 2024.</td></tr>
		<tr><td>One paper is accepted by CIBM, 2023.</td></tr>
		<tr><td>One paper is accepted by IEEE TMI, 2023.</td></tr>
		<tr><td>One paper is accepted by IEEE JBHI, 2023.</td></tr>
		<tr><td>One review is accepted by Journal of Image and Graphics, 2023.</td></tr> 
		<!-- <tr><td>One paper is accepted by CVIU, 2023.</td></tr>  -->
		<!-- <tr><td>One paper is accepted by ACPR, 2023.</td></tr>  -->
		<tr><td>One paper is accepted by MICCAI, 2023.</td></tr> 
		<tr><td>One paper is accepted by PR, 2023.</td></tr> 
		<tr><td>One paper is accepted by IEEE TMM, 2023.</td></tr> 
		<!-- <tr><td>One review is accepted by Mathematics, 2023.</td></tr>  -->
		<!-- <tr><td>One challenge report is accepted by CVPR Workshop, 2023.</td></tr> 	 -->
		<!-- <tr><td>One paper is accepted by CICP, 2023.</td></tr>  -->
		<tr><td>One paper is accepted by IEEE TIP, 2023.</td></tr> 
		<tr><td>One paper is accepted by IEEE TITS, 2023.</td></tr> 
		<!-- <tr><td>One paper is accepted by ICASSP, 2023.</td></tr>  -->
		<!-- <tr><td>One paper is accepted by ACM TOMM, 2022.</td></tr>  -->
		<tr><td>------Postdoc--------</td></tr> 
		<tr><td>One paper is accepted by Neurocomputing, 2022.</td></tr>
		<tr><td>One paper is accepted by IJCAI, 2022.</td></tr> 
		<!-- <tr><td>One challenge report is accepted by CVPR Workshop, 2022.</td></tr> 	 -->
		<!-- <tr><td>Two papers are accepted by CVPR Workshop, 2022.</td></tr>  -->
		<tr><td>One paper is accepted by IEEE TMM, 2022.</td></tr> 
		<tr><td>One paper is accepted by AAAI, 2021.</td></tr> 
		<tr><td>-------Ph.D---------</td></tr> 
		<tr><td>One paper is accepted by ICCV, 2021.</td></tr> 
		<tr><td>One paper is accepted by ACMMM, 2021.</td></tr> 
		<tr><td>One paper is accepted by IEEE TMM, 2021.</td></tr> 
		<tr><td>One paper is accepted by PR, 2021.</td></tr> 
		<tr><td>One paper is accepted by IEEE TMM 2021.</td></tr> 
		<!-- <tr><td>One paper is accepted by ICME, 2021.</td></tr> 	 -->
		<tr><td>One paper is accepted by IEEE TCSVT 2020.</td></tr> 
		<tr><td>One paper is accepted by IEEE TMM, 2020.</td></tr> 
		<!-- <tr><td>One paper is accepted by IEEE Access, 2020.</td></tr>  -->
		<tr><td>One paper is accepted by IEEE TNNLS, 2020.</td></tr> 
		<tr><td>One paper is accepted by IEEE TIP, 2020.</td></tr> 	
		<!-- <tr><td>Two papers are accepted by ICCV Workshop, 2019.</td></tr>  -->
		<!-- <tr><td>One challenge report is accepted by ICCV Workshop, 2019.</td></tr>  -->
		<!-- <tr><td>One paper is accepted by IET Image Processing, 2019.</td></tr> 	 -->
		<!-- <tr><td>One paper is accepted by ICONIP, 2018.</td></tr>  -->
		<!-- <tr><td>One paper is accepted by ACCV, 2018.</td></tr>  -->
		<tr><td>One paper is accepted by ECCV, 2018.</td></tr> 
		<!-- <tr><td>One challenge report is accepted by CVPR Workshop, 2018.</td></tr> 	 -->
	</tbody>
</table>
</div>


<h2>Honors &amp; Awards</h2>
<table style="border-spacing:2px">
	<tbody>
		<tr><td>The First Prize for Innovation Achievements in Industry-Academia-Research Cooperation in China, 2023.</td></tr>
		<tr><td>Research Fellowship Scheme, The Chinese University of Hong Kong, 2021.</td></tr> 
		<tr><td>Outstanding PhD Graduates in Shanghai, Shanghai, 2021.</td></tr> 
		<tr><td>Innovative and Intelligent Youth, East China Normal University, 2020. (0.5%)</td></tr> 	
		<tr><td>Outstanding Student, East China Normal University, 2020. (3.0%)</td></tr> 	
		<tr><td>Wisdom Scholarship, East China Normal University, 2020. (1.5%)</td></tr> 	
		<tr><td>Doctoral Research and Innovation Fund Project, East China Normal University, 2020.</td></tr> 
		<tr><td>ICCV Student Travel Award, 2019.</td></tr> 		
		<tr><td>Graduate Scholarship, East China Normal University, 2016-2020.</td></tr> 	
		<tr><td> The 1st place in <a href="http://www.vision.ee.ethz.ch/aim19/", target="_blank">"Example-based RAW to RGB Mapping Challenge"</a>, Track 2: Perceptual. <b>(ICCV-AIM)</b>, 2019.</td></tr>
		<tr><td> The 2nd place in <a href="http://www.vision.ee.ethz.ch/aim19/", target="_blank">"Example-based RAW to RGB Mapping Challenge"</a>, Track 1: Fidelity. <b>(ICCV-AIM)</b>, 2019.</td></tr>
		<tr><td> The 4th place and "Geek Award" in Alibaba - <a href="https://tianchi.aliyun.com/competition/entrance/231711/introduction", target="_blank">"Youku Video Enhancement and Super Resolution Challenge"</a> <b>(4/1514)</b>, 2019.</td></tr>
		<tr><td> The 3rd place in China Multimedia - <a href="https://github.com/rwenqi/ChinaMM18dehazing/blob/master/index.md", target="_blank">"Image Dehazing Challenge"</a>, <b>(ChinaMM)</b>, 2018.</td></tr>
		<tr><td> The 6th place and "Honorable Mention Award" in <a href="http://www.vision.ee.ethz.ch/ntire18/", target="_blank">"Image Dehazing Challenge".</a> <b>(CVPR-NTIRE)</b>, 2018.</td></tr>
		<!-- <tr><td>Ranked 24th in Jingdong Algorithm Challenge - "Potential User Prediction" <b>(24/4240)</b>, 2017.</td></tr> -->
	</tbody>
</table>


<h2>Research Experience</h2>
<ul>
	<li>
		<div style="float:left; text-align:left">The Chinese University of Hong Kong, Hong Kong. </div> <div style="float:right; text-align:right">2021--2022</div><br>
		<a href="https://aims.cuhk.edu.hk/converis/portal/detail/Person/73425234?auxfun=&lang=en_GB">Postdoctoral Fellow</a><br>
		Topic: Image resolution and medical image reconstruction<br>
		Supervisor: Prof. <a href="https://scholar.google.com.hk/citations?user=2yyTgRwAAAAJ&hl=zh-CN", target="_blank">Tieyong Zeng</a><br>
	</li>
	<li>
		<div style="float:left; text-align:left">Shenzhen University, Shenzhen. </div> <div style="float:right; text-align:right">2020.12.11--2021.01.30</div><br>
		Research Assistant (RA)<br>
		Topic: Medical Image Segmentation & Research on Uncertainty in Deep Learning<br>
		Supervisor: Prof. <a href="http://www.hebmlc.org/", target="_blank">Xizhao Wang</a> (IEEE Fellow, CAAI Fellow, IJMLC Editor-in-Chief)<br>
	</li>
	<li>
		<div style="float:left; text-align:left">The Chinese University of Hong Kong, Hong Kong. </div> <div style="float:right; text-align:right">2019.08.16--2019.09.30</div><br>
		Research Assistant (RA)<br>
		Topic: Image Compression<br>
		Supervisor: Prof. <a href="https://scholar.google.com.hk/citations?user=2yyTgRwAAAAJ&hl=zh-CN", target="_blank">Tieyong Zeng</a> (Director of <a href="http://cmai.math.cuhk.edu.hk/index.html">CMAI</a>)<br>
	</li>
	<li>
		<div style="float:left; text-align:left">The Chinese University of Hong Kong, Hong Kong. </div> <div style="float:right; text-align:right">2018.05.10--2018.09.10</div><br>
		Research Assistant (RA)<br>
		Topic: Image Restoration<br>
		Supervisor: Prof. <a href="https://scholar.google.com.hk/citations?user=2yyTgRwAAAAJ&hl=zh-CN", target="_blank">Tieyong Zeng</a> (Director of <a href="http://cmai.math.cuhk.edu.hk/index.html">CMAI</a>)<br>
	</li>
</ul>

<h2>Selected Publications [Total Citations: 4058] [Highest Citation: 1000] </h2>
<h3>#：Co-ﬁrst authors *：Corresponding author</h3>

<h3>Survey</h4>
<table id="tbPublications" width="100%">
	<tbody> 
	<tr>	
		<td width="206">
		<img src="./indexpics/ESWA2025.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="" target="_blank">Fast MRI Reconstruction: A Thorough Survey from Single-Modal to Multi-Modal<font color="red">【New】</font></a><br>
		Weiyi Lyu, Xinming Fang, Chaoyan Huang, Minhua Lu*, Jun Wang, Jun Shi, Juncheng Lia∗
		<p><em>Expert Systems with Applications</em> (<i><b>ESWA</b></i>), 2025.<br>
		<a href="", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
    <tr>	
		<td width="206">
		<img src="./indexpics/CSUR.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://dl.acm.org/doi/abs/10.1145/3659100" target="_blank">A Systematic Survey of Deep Learning-based Single-Image Super-Resolution</a><br>
		<b>Juncheng Li</b>, Zehua Pei, Wenjie Li, Guangwei Gao, Longguang Wang, Yingqian Wang, Tieyong Zeng
		<p><em>ACM Computing Surveys</em> (<i><b>CUSR</b></i>), 2024.<br>
		<iframe src="https://ghbtns.com/github-btn.html?user=CV-JunchengLi&repo=SISR-Survey
		&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150px" height="20px"></iframe><br>
		<a href="https://dl.acm.org/doi/abs/10.1145/3659100", target="_blank">[Paper]</a>
		<a href="https://github.com/CV-JunchengLi/SISR-Survey", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	<tr>	
		<td width="206">
		<img src="./indexpics/JIG.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/JIG_2023.pdf" target="_blank">Applications and Challenges of Deep Learning in Dental Imaging</a><br>
		Yang Zhao, <b>Juncheng Li*</b>, Bodong Cheng, Najun Niu, Longguang Wang, Guangwei Gao, Jun Shi
		<p><em>Journal of Image and Graphics</em> (<i><b>Chinese Journal</b></i>), 2023. <br>
        <a href="http://www.cjig.cn/jig/ch/reader/download_new_edit_content.aspx?edit_id=20230904140109001&file_no=202302090000001&journal_id=jig", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
 </tbody></table>


<h3>Medical Image Processing</h4>
<h4>Journal Papers</h4>
<table id="tbPublications" width="100%">
	<tbody>
	<tr>	
		<td width="206">
		<img src="./indexpics/HFMT.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="" target="_blank">MHigh-frequency Modulated Transformer for Multi-Contrast MRI Super-Resolution<font color="red">【New】</font></a><br>
		<b>Juncheng Li</b>, Hanhui Yang, Qiaosi Yi, Minhua Lu, Jun Shi, and Tieyong Zeng
		<p><em>IEEE Transactions on Medical Imaging</em> (<i><b>TMI</b></i>), 2025. <br>
        <a href="", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr>	
		<td width="206">
		<img src="./indexpics/TGCN-ICF-2.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/TGCN.pdf" target="_blank">Topological GCN Guided Improved Conformer for Detection of Hip Landmarks from Ultrasound Images<font color="red">【New】</font></a><br>
		Tianxiang Huang, Jing Shi, Ge Jin, <b>Juncheng Li</b>, Jun Wang, Qian Wang, Jun Du, and Jun Shi,
		<p><em>IEEE Journal of Biomedical and Health Informatics</em> (<i><b>JBHI</b></i>), 2025. <br>
        <a href="paper/TGCN.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr>	
		<td width="206">
		<img src="./indexpics/MCFN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/MCFN.pdf" target="_blank">Multimodal Co-attention Fusion Network with Online Data Augmentation for Cancer Subtype Classification</a><br>
		Saisai Ding, <b>Juncheng Li</b>, Jun Wang, Shihui Ying, and Jun Shi
		<p><em>IEEE Transactions on Medical Imaging</em> (<i><b>TMI</b></i>), 2024. <br>
        <a href="paper/MCFN.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	<tr>	
		<td width="206">
		<img src="./indexpics/ESWA.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://authors.elsevier.com/sd/article/S0957-4174(24)01121-7" target="_blank">Few Sampling Meshes-based 3D Tooth Segmentation via Region-Aware Graph Convolutional Network</a><br>
		Yang Zhao, Bodong Cheng, Najun Niu, Jun Wang, Tieyong Zeng, Guixu Zhang, Jun Shi, <b>Juncheng Li*</b>
		<p><em>Expert Systems with Applications</em> (<i><b>ESWA</b></i>), 2024. <br>
        <a href="", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	<tr>	
		<td width="206">
		<img src="./indexpics/JBHI2024.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/JBHI_2024.pdf" target="_blank">Involution Transformer based U-Net for Landmark Detection in Ultrasound Images for Diagnosis of Infantile DDH</a><br>
		Tianxiang Huang, Jing Shi*, <b>Juncheng Li</b>, Jun Wang, Jun Du, Jun Shi*
		<p><em>IEEE Journal of Biomedical and Health Informatics</em> (<i><b>JBHI</b></i>), 2024. <br>
        <a href="paper/JBHI_2024.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	<tr>	
		<td width="206">
		<img src="./indexpics/TMI2024-2.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="" target="_blank">Cost-Sensitive Weighted Contrastive Learning Based on Graph Convolutional Networks for Imbalanced Alzheimer’s Disease Staging</a><br>
		Yan Hu, Jun Wang*, Hao Zhu, <b>Juncheng Li</b>, Jun Shi
		<p><em>IEEE Transactions on Medical Imaging</em> (<i><b>TMI</b></i>), 2024. <br>
        <a href="", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
    <tr>	
		<td width="206">
		<img src="./indexpics/TMI2024-1.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="" target="_blank">Weakly Supervised Lesion Detection and Diagnosis for Breast Cancers with Partially Annotated Ultrasound Images</a><br>
		Jian Wang, Liang Qiao, Shichong Zhou, Jin Zhou, Jun Wang, <b>Juncheng Li</b>, Shihui Ying, Cai Chang, Jun Shi*
		<p><em>IEEE Transactions on Medical Imaging</em> (<i><b>TMI</b></i>), 2024. <br>
        <a href="", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	<tr>	
		<td width="206">
		<img src="./indexpics/Tooth.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/Fast-TGCN.pdf" target="_blank">A Fine-Grained Orthodontics Segmentation Model for 3D Intraoral Scan Data</a><br>
		<b>Juncheng Li</b>, Bodong Cheng, Najun Niu, Guangwei Gao, Shihui Ying, Jun Shi, Tieyong Zeng
		<p><em>Computers in Biology and Medicine</em> (<i><b>CIBM</b></i>), 2023. <br>
        <a href="https://www.sciencedirect.com/science/article/pii/S0010482523012866", target="_blank">[Paper]</a>
		<a href="https://reurl.cc/0vjLXY", target="_blank">[Dataset]</a>
		<a href="", target="_blank">[Code]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
    <tr>	
		<td width="206">
		<img src="./indexpics/EAMRI.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/CICP_2023.pdf" target="_blank">Fast MRI Reconstruction via Edge Attention </a><br>
		Hanhui Yang, <b>Juncheng Li*</b>, Lok Ming Lui, Shihui Ying, Jun Shi, and Tieyong Zeng*
		<p><em>Communications in Computational Physics</em> (<i><b>CICP</b></i>), 2023. <br>
        <a href="https://arxiv.org/pdf/2304.11400.pdf", target="_blank">[Paper]</a>
		<a href="", target="_blank">[Code]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
    <tr>	
		<td width="206">
		<img src="./indexpics/TMI.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/TMI_2023.pdf" target="_blank">Pseudo-Data based Self-Supervised Federated Learning for Classification of Histopathological Images</a><br>
			Yuanming Zhang, Zheng Li, Xiangmin Han, Saisai Ding, <b>Juncheng Li</b>, Jun Wang, Shihui Ying, Jun Shi*
		<p><em>IEEE Transactions on Medical Imaging</em> (<i><b>TMI</b></i>), 2023. <br>
        <a href="https://arxiv.org/pdf/2305.15773.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	<tr>	
		<td width="206">
		<img src="./indexpics/JBHI.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/JBHI_2023.pdf" target="_blank">Multi-scale Efficient Graph-Transformer for Whole Slide Image Classification</a><br>
		Saisai Ding, <b>Juncheng Li</b>, Jun Wang, Shihui Ying, Jun Shi*
		<p><em>IEEE Journal of Biomedical and Health Informatics</em> (<i><b>JBHI</b></i>), 2023. <br>
        <a href="https://arxiv.org/pdf/2305.15773.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
</tbody></table>


<h4>Conference Papers</h4>
<table id="tbPublications" width="100%">
	<tbody>
	<tr>	
		<td width="206">
		<img src="./indexpics/TGCN-ICF.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/MICCAI_2024.pdf" target="_blank">Topological GCN for Improving Detection of Hip Landmarks from B-Mode Ultrasound Images<font color="red">【New】</font></a><br>
		Tianxiang Huang, Jing Shi, Ge Jin, <b>Juncheng Li</b>, Jun Wang, Jun Du, and Jun Shi
		<p><em>International Conference on Medical Image Computing and Computer-Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2024. <br>
		<font color="red">Top medical image processing conference.（Oral Presentation）</font><br>
        <a href="paper/MICCAI_2024.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	<tr>	
		<td width="206">
		<img src="./indexpics/MICCAI.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/MICCAI_2023.pdf" target="_blank">Multi-Scale Prototypical Transformer for Whole Slide Image Classification</a><br>
		Saisai Ding, Jun Wang, <b>Juncheng Li</b>, and Jun Shi*
		<p><em>International Conference on Medical Image Computing and Computer-Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2023. <br>
		<font color="red">Top medical image processing conference.</font><br>
        <a href="https://link.springer.com/chapter/10.1007/978-3-031-43987-2_58", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
</tbody></table>




<h3>Image Restoration and Enhancement</h4>
<h4>Journal Papers</h4>
<table id="tbPublications" width="100%">
	<tbody>
	<tr>	
		<td width="206">
		<img src="./indexpics/TCSVT2024.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://ieeexplore.ieee.org/abstract/document/10654332" target="_blank">WeaFU: Weather-Informed Image Blind Restoration via Multi-Weather Distribution Diffusion<font color="red">【New】</font></a><br>
		Bodong Cheng, <b>Juncheng Li*</b>, Jun Shi, Yingying Fang, Guixu Zhang, Yin Chen, Tieyong Zeng, and Zhi Li*
		<p><em>IEEE Transactions on Circuits and Systems for Video Technology</em> (<i><b>TCSVT</b></i>), 2024. <br>
		<a href="paper/TCSVT2024.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/CFIN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="" target="_blank">Cross-Receptive Focused Inference Network for Lightweight Image Super-Resolution (<font color="red"><i><b>ESI Highly Cited Paper, 25.01</b></i></font>)<br></a><br>
		Wenjie Li, <b>Juncheng Li</b>, Guangwei Gao, Weihong Deng, Jiantao Zhou, Jian Yang, and Guo-Jun Qi
		<p><em>IEEE Transactions on Multimedia</em> (<i><b>TMM</b></i>), 2024. <br>
		<a href="paper/CFIN.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/EWT.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://www.sciencedirect.com/science/article/pii/S0893608024003022?dgcid=coauthor" target="_blank">EWT: Efficient Wavelet-Transformer for Single Image Denoising</a><br>
		<b>Juncheng Li</b>, Bodong Cheng, Ying Chen, Guangwei Gao, Jun Shi, and Tieyong Zeng
		<p><em>Neural Networks</em> (<i><b>NN</b></i>), 2024. <br>
		<a href="paper/NN_2024.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/CTCNet.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://arxiv.org/pdf/2204.08696.pdf" target="_blank">CTCNet: A CNN-Transformer Cooperation Network for Face Image Super-Resolution</a> (<font color="red"><i><b>ESI Highly Cited Paper, 24.05, 24.09, 24.11, 25.01</b></i></font>)<br>
		Guangwei Gao#, Zixiang Xu#, <b>Juncheng Li*</b>, Jian Yang, Tieyong Zeng, and Guo-Jun Qi.
		<p><em>IEEE Transactions on Image Processing</em> (<i><b>IEEE TIP</b></i>), 2023. <br>
		<a href="paper/CTCNet.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/FBSNet.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://ieeexplore.ieee.org/abstract/document/9732215" target="_blank">FBSNet: A Fast Bilateral Symmetrical Network for Real-Time Semantic Segmentation</a> (<font color="red"><i><b>ESI Highly Cited Paper, 23.11, 24.01, 24.05, 24.07, 24.09, 24.11, 25.01</b></i></font>)<br>
		Guangwei Gao#, Guoan Xu#, <b>Juncheng Li*</b>, Yi Yu*, Huimin Lu, and Jian Yang
		<p><em>IEEE Transactions on Multimedia</em> (<i><b>IEEE TMM</b></i>), 2022. <br>
		<a href="paper/FBSNet.pdf", target="_blank">[Paper]</a>
		<a href="https://guangweigao.github.io/TMM22/FBSNet.html", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/ASRN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/ASRN.pdf" target="_blank">Adjustable Super-Resolution Network via Deep Supervised Learning and Progressive Self-Distillation</a><br>
		<b>Juncheng Li</b>, Faming Fang*, Tieyong Zeng, Guixu Zhang, and Xizhao Wang.
		<p><em>Neurocomputing</em> (<i><b>NC</b></i>), 2022. <br>
		<a href="paper/ASRN.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/MSTN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://ieeexplore.ieee.org/document/9473023" target="_blank">Efficient and Accurate Multi-scale Topological Network for Single Image Dehazing</a><br>
		Qiaosi Yi#, <b>Juncheng Li#</b>, Faming Fang*, Aiwen Jiang, and Guixu Zhang
		<p><em>IEEE Transactions on Multimedia</em> (<i><b>IEEE TMM</b></i>), 2021. <br> 
		<a href="https://ieeexplore.ieee.org/document/9473023", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/MDCN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/TCSVT_2020.pdf" target="_blank">MDCN: Multi-scale Dense Cross Network for Image Super-Resolution</a><br>
		<b>Juncheng Li</b>, Faming Fang, Jiaqian Li, Kangfu Mei, and Guixu Zhang*.
		<p><em>IEEE Transactions on Circuits and Systems for Video Technology</em> (<i><b>IEEE TCSVT</b></i>), 2020. <br>
        <a href="paper/TCSVT_2020.pdf", target="_blank">[Paper]</a>
		<a href="https://github.com/MIVRC/MDCN-PyTorch", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/TCSVT2020_MDCN", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/LPNet.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/TMM_2020.pdf" target="_blank">Luminance-aware Pyramid Network for Low-light Image Enhancement</a><br>
		Jiaqian Li#, <b>Juncheng Li#</b>, Faming Fang*, Fang Li, and Guixu Zhang.
		<p><em>IEEE Transactions on Multimedia</em> (<i><b>IEEE TMM</b></i>), 2020. <br>
		<a href="paper/TMM_2020.pdf", target="_blank">[Paper]</a>
		<a href="https://github.com/MIVRC/LPNet-PyTorch", target="_blank">[Code]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/MLEFGN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/TNNLS_2020.pdf" target="_blank">Multi-level Edge Features Guided Network for Image Denoising</a><br>
		Faming Fang, <b>Juncheng Li</b>, Yiting Yuan, Tieyong Zeng*, and Guixu Zhang*.
		<p><em>IEEE Transactions on Neural Networks and Learning Systems</em> (<i><b>IEEE TNNLS</b></i>), 2020. <br>
		<font color="red">Author names alphabetically.</font><br> 
		<!-- <font color="red">This work was completed during the visit of CUHK.</font><br>  -->
		<!-- <iframe src="https://ghbtns.com/github-btn.html?user=MIVRC&repo=MLEFGN-PyTorch&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150px" height="20px"></iframe><br> -->
        <a href="paper/TNNLS_2020.pdf", target="_blank">[Paper]</a>
		<a href="https://github.com/MIVRC/MLEFGN-PyTorch", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/TNNLS2020_MLEFGN", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	

    <tr>	
		<td width="206">
		<img src="./indexpics/SeaNet.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/TIP_2020.pdf" target="_blank">Soft-edge Assisted Network for Single Image Super-Resolution <font color="red">【Hot】</font></a><br>
		Faming Fang, <b>Juncheng Li</b>, and Tieyong Zeng*.
		<p><em>IEEE Transactions on Image Processing</em> (<i><b>IEEE TIP</b></i>), 2020. <br>
		<font color="red">Author names alphabetically.</font><br> 
		<!-- <font color="red">This work was completed during the visit of CUHK.</font><br>  -->
		<!-- <iframe src="https://ghbtns.com/github-btn.html?user=MIVRC&repo=SeaNet-PyTorch&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150px" height="20px"></iframe><br> -->
        <a href="paper/TIP_2020.pdf", target="_blank">[Paper]</a>
		<a href="https://github.com/MIVRC/SeaNet-PyTorch", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/TIP2020_SEANET", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
</tbody></table>



<h4>Conference Papers</h4></table>
<table id="tbPublications" width="100%">
	<tr>	
		<td width="206">
		<img src="./indexpics/CVPR2024.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">Learning Coupled Dictionaries from Unpaired Data for Image Super-Resolution <font color="red">【New】</font></a><br>
		Longguang Wang, <b>Juncheng Li</b>, Yingqian Wang, Qingyong Hu, and Yulan Guo*.
		<p><em>Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2024. <br>
		<font color="red">Top computer vision conference.</font><br>
		<a href="paper/CVPR.pdf", target="_blank">[Paper]</a>
		<a href="", target="_blank">[Poster]</a>
		<a href="", target="_blank">[Code]</a>
		</td>
	</tr>
	<tr></tr>
	<tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/IJCAI.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="http://arxiv.org/abs/2204.13286" target="_blank">Lightweight Bimodal Network for Single-Image Super-Resolution via Symmetric CNN and Recursive Transformer</a><br>
		Guangwei Gao#, Zhengxue Wang#, <b>Juncheng Li*</b>, Wenjie Li, Yi Yu, and Tieyong Zeng
		<p><em>International Joint Conference on Artificial Intelligence</em> (<i><b>IJCAI</b></i>), 2022. <br>
		<font color="red">Top artificial intelligence conference. Oral Presentation</font><br>
		<a href="paper/IJCAI2022.pdf", target="_blank">[Paper]</a>
		<a href="https://github.com/IVIPLab/LBNet", target="_blank">[Code]</a>
		<a href="https://guangweigao.github.io/IJCAI22/LBNet.html", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/AAAI.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">Feature Distillation Interaction Weighting Network for Lightweight Image Super-Resolution</a><br>
		Guangwei Gao#, Wenjie Li#, <b>Juncheng Li*</b>, Fei Wu, Huimin Lu, and Yi Yu
		<p><em>Association for the Advancement of Artificial Intelligence</em> (<i><b>AAAI</b></i>), 2022. <br>
		<font color="red">Top artificial intelligence conference.</font><br>
		<a href="paper/AAAI.pdf", target="_blank">[Paper]</a>
		<a href="poster/AAAI-poster.pdf", target="_blank">[Poster]</a>
		<a href="https://github.com/IVIPLab/FDIWN", target="_blank">[Code]</a>
		<a href="https://guangweigao.github.io/AAAI22/FDIWN.html", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/ACMMM.jpeg" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="paper/ACMMM_2021.pdf" target="_blank">Feedback Network for Mutually Boosted Stereo Image Super-Resolution and Disparity Estimation</a><br>
		Qinyan Dai, <b>Juncheng Li</b>, Qiaosi Yi, Faming Fang*, and Guixu Zhang.
		<p><em>ACM International Conference on Multimedia</em> (<i><b>ACMMM</b></i>), 2021. <br>
		<font color="red">Top multimedia conference.</font><br>
		<a href="paper/ACMMM_2021.pdf", target="_blank">[Paper]</a>
		<a href="poster/ACMMM_poster.pdf", target="_blank">[Poster]</a>
		<a href="https://github.com/MIVRC/SSRDEFNet-PyTorch", target="_blank">[Code]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/ICCV2021.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="paper/ICCV_2021.pdf" target="_blank">Structure-Preserving Deraining with Residue Channel Prior Guidance</a><br>
		Qiaosi Yi, <b>Juncheng Li</b>, Qinyan Dai, Faming Fang*, Guixu Zhang, and Tieyong Zeng.
		<p><em>International Conference on Computer Vision</em> (<i><b>ICCV</b></i>), 2021. <br>
		<font color="red">Top computer vision conference.</font><br>
		<a href="paper/ICCV_2021.pdf", target="_blank">[Paper]</a>
		<a href="poster/ICCV_poster.pdf", target="_blank">[Poster]</a>
		<a href="https://github.com/Joyies/SPDNet", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/ICCV2021_SPDNet", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/MSRN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/ECCV_2018.pdf" target="_blank">Multi-scale Residual Network for Image Super-Resolution <font color="red">【Hot】[Citations: 970+]</font></a><br>
		<b>Juncheng Li</b>, Faming Fang*, Kangfu Mei, and Guixu Zhang.
		<p><em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2018.<br>
		<font color="red">Top computer vision conference.</font><br>
		<iframe src="https://ghbtns.com/github-btn.html?user=MIVRC&repo=MSRN-PyTorch&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150px" height="20px"></iframe>
		<iframe src="https://ghbtns.com/github-btn.html?user=MIVRC&repo=MSRN-PyTorch&type=fork&count=true&size=small" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe><br>
		<a href="paper/ECCV_2018.pdf", target="_blank">[Paper]</a>
        <a href="poster/MSRN-poster.pdf", target="_blank">[Poster]</a>
		<a href="https://github.com/MIVRC/MSRN-PyTorch", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/ECCV2018_MSRN", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
</tbody></table>



<h4>Workshop Papers</h4></table></table>
<table id="tbPublications" width="100%">
	<tr>	
		<td width="206">
		<img src="./indexpics/ESRT.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://arxiv.org/pdf/2108.11084.pdf" target="_blank">Transformer for Single Image Super-Resolution <font color="red">【Hot】[Citations: 600+]</font></a><br>
		Zhisheng Lu#, <b>Juncheng Li#</b>, Hong Liu*, Chaoyan Huang, Linlin Zhang, and Tieyong Zeng
		<p><em>The Conference on Computer Vision and Pattern Recognition Workshop</em> (<i><b>CVPR Workshop</b></i>), 2022. <br>
		<font color="red">NTIRE</font><br>
		<iframe src="https://ghbtns.com/github-btn.html?user=luissen&repo=ESRT&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150px" height="20px"></iframe>
		<iframe src="https://ghbtns.com/github-btn.html?user=luissen&repo=ESRT&type=fork&count=true&size=small" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe><br>
		<a href="paper/ESRT.pdf", target="_blank">[Paper]</a>
		<a href="paper/ESRT-supp.pdf", target="_blank">[Supp]</a>
		<a href="poster/ESRT.pdf", target="_blank">[Poster]</a>
		<a href="https://github.com/luissen/ESRT", target="_blank">[Code]</a>
		<a href="projects/ESRT", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/MDRN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://arxiv.org/pdf/2204.13873.pdf" target="_blank">Multiple Degradation and Reconstruction Network for Single Image Denoising via Knowledge Distillation </a><br>
		<b>Juncheng Li</b>, Hanhui Yang, Qiaosi Yi, Faming Fang, Guangwei Gao, Tieyong Zeng*, and Guixu Zhang
		<p><em>The Conference on Computer Vision and Pattern Recognition Workshop</em> (<i><b>CVPR Workshop</b></i>), 2022. <br>
		<font color="red">NTIRE</font><br>
		<a href="paper/MDRN.pdf", target="_blank">[Paper]</a>
		<a href="poster/MDRN.pdf", target="_blank">[Poster]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/SRRFN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/ICCVW_LCI_2019.pdf" target="_blank">Lightweight and Accurate Recursive Fractal Network for Image Super-Resolution</a><br>
		<b>Juncheng Li</b>, Yiting Yuan, Kangfu Mei, and Faming Fang*.
		<p><em>International Conference on Computer Vision Workshop</em> (<i><b>ICCV Workshop</b></i>), 2019. <br>
		<font color="red">Oral Presentation. Student Travel Award.</font><br>
		<a href="paper/ICCVW_LCI_2019.pdf", target="_blank">[Paper]</a>
        <a href="poster/ICCVW_LCI_poster.pdf", target="_blank">[Poster]</a>
        <a href="slides/ICCVW_LCI_slides.pdf", target="_blank">[Slides]</a>
		<a href="https://github.com/MIVRC/SRRFN-PyTorch", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/ICCVW2019_SRRFN", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
</tbody></table>


<!-- <h4>Selected Challenge Reports</h4>
<table id="tbPublications" width="100%">
	<tbody>
	<tr>	
		<td width="206">
		<img src="./indexpics/NTIRE2022.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://arxiv.org/pdf/2204.09197.pdf" target="_blank">NTIRE 2022 Challenge on Stereo Image Super-Resolution: Methods and Results</a><br>
		<p><em>CVPR NTIRE</em>, 2022.<br>
		Longguang Wang, Yulan Guo*, Yingqian Wang, <b>Juncheng Li</b>, Shuhang Gu, Radu Timofte <br>
		<font color="red">Co-Organizer</font><br>
		<iframe src="https://ghbtns.com/github-btn.html?user=The-Learning-And-Vision-Atelier-LAVA&repo=Stereo-Image-SR&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150px" height="20px"></iframe><br>
		<a href="paper/NTIRE2022.pdf", target="_blank">[Paper]</a>
		<a href="video/NTIRE Stereo Image SR Challenge.mp4", target="_blank">[Video]</a>
		<a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2022", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>

	<tr>	
		<td width="206">
		<img src="./indexpics/NTIRE2023.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/NTIRE2023.pdf" target="_blank">NTIRE 2023 Challenge on Stereo Image Super-Resolution: Methods and Results</a><br>
		<p><em>CVPR NTIRE</em>, 2023.<br>
		Longguang Wang, Yulan Guo*, Yingqian Wang, <b>Juncheng Li</b>, Shuhang Gu, Radu Timofte <br>
		<font color="red">Co-Organizer</font><br>
		<iframe src="https://ghbtns.com/github-btn.html?user=The-Learning-And-Vision-Atelier-LAVA&repo=Stereo-Image-SR&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150px" height="20px"></iframe><br>
		<a href="paper/NTIRE2023.pdf", target="_blank">[Paper]</a>
		<a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2023", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
 </tbody></table> -->


<h2>Academic Services</h2>
<h3>Guest Editor</h3>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> <a href="https://www.mdpi.com/journal/mathematics/special_issues/TSQMQ830KB", target="_blank">Special issue "Mathematical Techniques and Artificial Intelligence in Image Processing" on the Journal of Mathematics.</a></td>
		</tr>
		<tr>
			<td> <a href="https://ietresearch.onlinelibrary.wiley.com/hub/journal/17519640/homepage/cfp", target="_blank">Special issue "Advanced Image Restoration and Enhancement in the Wild" on IET Computer Version.</a></td>
		</tr>
		<tr>
			<td> <a href="https://www.mdpi.com/journal/mathematics/special_issues/V5G28PQF0B", target="_blank">Special issue "Representation Learning for Computer Vision and Pattern Recognition" on the Journal of Mathematics.</a></td>
		</tr>
	</tbody>
</table>

<h3>Co-Organizer</h3>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2024", target="_blank">CVPR-NTIRE 2024: Stereo Image Super-Resolution Challenge</a></td>
		</tr>
		<tr>
			<td> <a href="https://ericlab.org/acpr2023/workshops/", target="_blank">ACPR 2023 Workshop: Representation Learning for Computer Vision and Pattern Recognition</a></td>
		</tr>
		<tr>
			<td> <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2023", target="_blank">CVPR-NTIRE 2023: Stereo Image Super-Resolution Challenge</a></td>
		</tr>
		<tr>
			<td> <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2022", target="_blank">CVPR-NTIRE 2022: Stereo Image Super-Resolution Challenge</a></td>
		</tr>
		<tr>
			<td> <a href="https://guangweigao.github.io/icme22ss.html", target="_blank">IEEE ICME 2021 Special Session: Advanced Representation Learning for Robust Multimedia Image Understanding</a></td>
		</tr>
	</tbody>
</table>

<h3>Program Committee Member (PC member)</h3>
<table id="tbTeaching" border="0" width="100%">
		<tbody>
			<tr>
				<td> <a href="https://ecai2025.org/", target="_blank">28th European Conference on Artificial Intelligence (ECAI-25), 2025.</a></td>
			</tr>
			<tr>
				<td> <a href="https://2025.ijcai.org/", target="_blank">34th International Joint Conference on Artificial Intelligence (IJCAI-25), 2025.</a></td>
			</tr>
			<tr>
				<td> <a href="https://data.vision.ee.ethz.ch/cvl/ntire22/", target="_blank">CVPR, New Trends in Image Restoration and Enhancement workshop and challenges on image and video processing (NTIRE), 2022, 2023, 2024.</a></td>
			</tr>
			<tr>
				<td> <a href="https://data.vision.ee.ethz.ch/cvl/aim22/", target="_blank">ICCV, AIM: Advances in Image Manipulation workshop and challenges, 2022.</a></td>
			</tr>
		</tbody>
</table>

<!-- <h3>Technical Program Committee Member</h3>
<table id="tbTeaching" border="0" width="100%">
		<tbody>
			<tr>
				<td> <a href="https://www.ammcs.org/committee", target="_blank">The 2nd International Conference on Applied Mathematics, Modeling and Computer Simulation, 2022.</a></td>
			</tr>
			<tr>
				<td> <a href="http://www.tdiconference.com/wabd2022.html", target="_blank">Transdisciplinary Information Sciences conferences - Workshop on Algorithm and Big Data, 2022.</a></td>
			</tr>
			<tr>
				<td> <a href="https://www.iaria.org/conferences2021/ComICAS21.html", target="_blank">International Conference on Autonomic and Autonomous Systems (ICAS), 2021.</a></td>
			</tr>
		</tbody>
</table> -->

<h3>Journal Reviewer</h3>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</td>
		</tr>
		<tr>
			<td> IEEE Transactions on Image Processing (TIP)</td>
		</tr>
		<tr>
			<td> IEEE Transactions on Neural Networks and Learning System (TNNLS)</td>
		</tr>
		<tr>
			<td> IEEE Transactions on Cybernetics (TCYB)</td>
		</tr>
		<tr>
			<td> IEEE Transactions on Multimedia (TMM)</td>
		</tr>
		<tr>
			<td> IEEE Transactions on Broadcasting (TB)</td>
		</tr>
		<tr>
			<td> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</td>
		</tr>
		<tr>
			<td> Medical Image Analysis</td>
		</tr>
		<tr>
			<td> IEEE Journal of Biomedical and Health Informatics (JBHI)</td>
		</tr>
		<tr>
			<td> Computers in Biology and Medicine (CIBM)</td>
		</tr>
		<tr>
			<td> Information Science (INS)</td>
		</tr>
		<tr>
			<td> Pattern Recognition (PR)</td>
		</tr>
        <tr>
			<td> Knowledge-Based Systems (KBS)</td>
		</tr>
		<tr>
			<td> Computer Vision and Image Understanding (CVIU)</td>
		</tr>
		<tr>
			<td> IEEE Signal Processing Letters (SPL)</td>
		</tr>
		<tr>
			<td> ...</td>
		</tr>
	</tbody>
</table>


<h3>Conference Reviewer</h3>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> Conference on Computer Vision and Pattern Recognition (CVPR)</td>
		</tr>
		<tr>
			<td> European Conference on Computer Vision (ECCV)</td>
		</tr>
		<tr>
			<td> International Conference on Computer Vision (ICCV)</td>
		</tr>
		<tr>
			<td> International Joint Conference on Artificial Intelligence (IJCAI)</td>
		</tr>
		<tr>
			<td> ACM Multimedia (ACMMM)</td>
		</tr>
		<tr>
			<td> International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</td>
		</tr>
		<!-- <tr>
			<td> Advances in Image Manipulation workshop and challenges (AIM)</td>
		</tr>
		<tr>
			<td> New Trends in Image Restoration and Enhancement workshop
				and challenges on image and video processing (NTIRE)</td>
		</tr> -->
		<!-- <tr>
			<td> IEEE International Conference on Multimedia & Expo (ICME)</td>
		</tr>
		<tr>
			<td> International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</td>
		</tr>
		<tr>
			<td> The British Machine Vision Conference (BMVC)</td>
		</tr>
		<tr>
			<td>International Conference on Pattern Recognition (ICPR)</td>
		</tr> -->
		<tr>
			<td> ...</td>
		</tr>
	</tbody>
</table>

<!-- <h3>Association Member</h3>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> Member of CVF/CCF/CSIG/CAAI</td>
		</tr>
		<tr>
			<td> Founder of <a href="https://github.com/MIVRC", target="_blank">MIVRC</a> </td>
		</tr>
		<tr>
			<td> Founder of CLF Studio</td>
		</tr>
	</tbody>
</table> -->

<!-- <h2>Keynotes</h2>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>	
			<td width="110">
					<img src="./reports/CUHK.png" width="100" style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td> Structure-Preserving Deraining with Residue Channel Prior Guidance<br>
				<p><em>Internal meeting, Chinese University of Hong Kong.</em><br>
				Hong Kong, China, 2021.08.20<br>
				<a href="slides/CUHK.pdf", target="_blank">[Slides]</a>
			</td>
		</tr>

		<tr>	
			<td width="110">
					<img src="./reports/SZ.png" width="100" style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td> Exploration and Construction of Lightweight Image Restoration Model<br>
				<p><em>Institute of Big Data Technology and Application, School of Computer and Software, Shenzhen University.</em><br>
				Shenzhen, China, 2020.12.21.<br>
				<a href="poster/SZ.pdf", target="_blank">[Poster]</a>
				<a href="slides/SZ-Lightweight.pdf", target="_blank">[Slides]</a>
			</td>
		</tr>

		<tr>	
			<td width="110">
				<img src="./reports/ICCV.png" width="100" style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td> Lightweight and Accurate Recursive Fractal Network for Image Super-Resolution<br>
				<p><em>IEEE International Conference on Computer Vision Workshop</em> (<i><b>ICCVW</b></i>).<br>
				Seoul, Korea, 2019.11.02.<br>
				<a href="slides/ICCVW_LCI_slides.pdf", target="_blank">[Slides]</a>
			</td>
		</tr>
	</tbody>
</table> -->


 <!--
<h2>Meeting (2016.9-Now)</h2>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> <font color="red">CSIAM-2020</font>, Changsha, China, 2020.</td>
		</tr>
        <tr>
			<td> <font color="red">PRCV-2020</font>, Nanjing, China, 2020.</td>
		</tr>
		<tr>
			<td> <font color="red">SCF-2020</font>, Shanghai, China, 2019.</td>
		</tr>
		<tr>
			<td> <font color="red">NeurlPS-Shanghai</font>, Shanghai, China, 2019.</td>
		</tr>
		<tr>
			<td> <font color="red">ICCV-2019</font>, Seoul, Korea, 2019.</td>
		</tr>
		<tr>
			<td> <font color="red">YouKu-VSRE-2019</font>, Hanzhou, China, 2019.</td>
		</tr>
		<tr>
			<td> <font color="red">RAMIDS-2019</font>, Shanghai Jiao Tong University, Shanghai, China, 2019.</td>
		</tr>
		<tr>
			<td> <font color="red">VALSE-2019</font>, Hefei, China, 2019.</td>
		</tr>
		<tr>
			<td> <font color="red">ECCV-2018</font>, Munich, Germany, 2018.</td>
		</tr>
		<tr>
			<td> <font color="red">ECCV Pre-Conference</font>, Tencent, Shenzhen, China, 2018.</td>
		</tr>
		<tr>
			<td> <font color="red">AWS Reinvent</font>, Shanghai, China, 2018.</td>
		</tr>
		<tr>
			<td> <font color="red">MICS-2017</font>, Shanghai Jiao Tong University, Shanghai, China, 2017.</td>
		</tr>
		<tr>
			<td> <font color="red">FLAIR-2017</font>, Shanghai, China, 2017.</td>
		</tr>
		<tr>
			<td> <font color="red">VALSE-2017</font>, Xiamen University, Xiamen, China, 2017.</td>
		</tr>
		<tr>
			<td> <font color="red">Tianyuan Class</font>, Zhejiang University, Hanzhou, China, 2017.</td>
		</tr>
		<tr>
			<td> <font color="red">ROS Class</font>, East China University, Shanghai, China, 2017.</td>
		</tr>
		<tr>
			<td> <font color="red">MLA-2016</font>, Nanjing University, Nanjing, China, 2016.</td>
		</tr>
		<tr>
			<td> <font color="red">Youth Vision Seminar</font>, ShanghaiTech University, Shanghai, China, 2016.</td>
		</tr>
	</tbody>
</table>-->

<div id="footer">
	<div id="footer-text"></div>
</div>

<p>
<center>
<div>
 <!--<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=lSzpjw-jyYmDQRUSrVJGAFZBVU3oVwp87NxUFm1Zt_w'></script>
</div>-->  
<br>
&copy; Juncheng Li | Last updated: 2024-12
</center>
</p>

</div>
</body></html>
